{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Industry Applications"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Recipe 5-1. Implementing Multiclass Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from textblob import TextBlob\n",
    "from nltk.stem import PorterStemmer\n",
    "from textblob import Word\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "import sklearn.feature_extraction.text as text\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from io import StringIO\n",
    "import seaborn as sns\n",
    "\n",
    "#Importing the data which was downloaded in the last step\n",
    "\n",
    "Data = pd.read_csv(\"/Consumer_Complaints.csv\",encoding='latin-1')\n",
    "\n",
    "#Understanding the columns\n",
    "\n",
    "Data.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Selecting required columns and rows\n",
    "Data = Data[['product', 'consumer_complaint_narrative']]\n",
    "Data = Data[pd.notnull(Data['consumer_complaint_narrative'])]\n",
    "\n",
    "# See top 5 rows\n",
    "Data.head()\n",
    "\n",
    "# Factorizing the category column\n",
    "Data['category_id'] = Data['product'].factorize()[0]\n",
    "\n",
    "Data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check the distriution of complaints by category\n",
    "Data.groupby('product').consumer_complaint_narrative.count()\n",
    "\n",
    "\n",
    "# Lets plot it and see\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "Data.groupby('product').consumer_complaint_narrative.count().plot.bar(ylim=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the data into train and validation\n",
    "\n",
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(Data['consumer_complaint_narrative'], Data['product'])\n",
    "\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "valid_y = encoder.fit_transform(valid_y)\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "\n",
    "tfidf_vect.fit(Data['consumer_complaint_narrative'])\n",
    "xtrain_tfidf =  tfidf_vect.transform(train_x)\n",
    "xvalid_tfidf =  tfidf_vect.transform(valid_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = linear_model.LogisticRegression().fit(xtrain_tfidf, train_y)\n",
    "\n",
    "\n",
    "# Model summary\n",
    "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
    "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
    "          verbose=0, warm_start=False)\n",
    "\n",
    "# Checking accuracy\n",
    "\n",
    "accuracy = metrics.accuracy_score(model.predict(xvalid_tfidf), valid_y)\n",
    "print (\"Accuracy: \", accuracy)\n",
    "\n",
    "# Classification report\n",
    "\n",
    "print(metrics.classification_report(valid_y, model.predict(xvalid_tfidf),target_names=Data['product'].unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "\n",
    "conf_mat = confusion_matrix(valid_y, model.predict(xvalid_tfidf))\n",
    "\n",
    "# Vizualizing confusion matrix\n",
    "\n",
    "category_id_df = Data[['product', 'category_id']].drop_duplicates().sort_values('category_id')\n",
    "category_to_id = dict(category_id_df.values)\n",
    "id_to_category = dict(category_id_df[['category_id', 'product']].values)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d', cmap=\"BuPu\",\n",
    "            xticklabels=category_id_df[['product']].values, yticklabels=category_id_df[['product']].values)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prediction example\n",
    "\n",
    "texts = [\"This company refuses to provide me verification and validation of debt\"+ \n",
    "         \"per my right under the FDCPA. I do not believe this debt is mine.\"]\n",
    "text_features = tfidf_vect.transform(texts)\n",
    "predictions = model.predict(text_features)\n",
    "print(texts)\n",
    "print(\"  - Predicted as: '{}'\".format(id_to_category[predictions[0]]))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Recipe 5-2. Implementing Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "#Read the data\n",
    "df = pd.read_csv('Reviews.csv')\n",
    "\n",
    "# Look at the top 5 rows of the data\n",
    "df.head(5)\n",
    "\n",
    "# Understand the data types of the columns\n",
    "df.info()\n",
    "\n",
    "# Looking at the summary of the reviews.\n",
    "df.Summary.head(5)\n",
    "\n",
    "# Looking at the description of the reviews\n",
    "df.Text.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "from textblob import Word\n",
    "\n",
    "# Lower casing and removing punctuations\n",
    "df['Text'] = df['Text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "df['Text'] = df['Text'].str.replace('[^\\w\\s]','')\n",
    "\n",
    "# Removal of stop words\n",
    "stop = stopwords.words('english')\n",
    "df['Text'] = df['Text'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "\n",
    "# Spelling correction\n",
    "df['Text'] = df['Text'].apply(lambda x: str(TextBlob(x).correct()))\n",
    "\n",
    "# Lemmatization\n",
    "df['Text'] = df['Text'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "\n",
    "df.Text.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a new data frame “reviews” to perform exploratory data analysis upon that\n",
    "\n",
    "reviews = df\n",
    "\n",
    "# Dropping null values\n",
    "reviews.dropna(inplace=True) \n",
    "\n",
    "# The histogram reveals this dataset is highly unbalanced towards high rating. \n",
    "\n",
    "reviews.Score.hist(bins=5,grid=False)\n",
    "plt.show()\n",
    "print(reviews.groupby('Score').count().Id)\n",
    "\n",
    "# To make it balanced data, we sampled each score by the lowest n-count from above. (i.e. 29743 reviews scored as '2')\n",
    "\n",
    "score_1 = reviews[reviews['Score'] == 1].sample(n=29743)\n",
    "score_2 = reviews[reviews['Score'] == 2].sample(n=29743)\n",
    "score_3 = reviews[reviews['Score'] == 3].sample(n=29743)\n",
    "score_4 = reviews[reviews['Score'] == 4].sample(n=29743)\n",
    "score_5 = reviews[reviews['Score'] == 5].sample(n=29743)\n",
    "\n",
    "# Here we recreate a 'balanced' dataset.\n",
    "reviews_sample = pd.concat([score_1,score_2,score_3,score_4,score_5],axis=0)\n",
    "reviews_sample.reset_index(drop=True,inplace=True)\n",
    "\n",
    "# Printing count by 'Score' to check dataset is now balanced.\n",
    "print(reviews_sample.groupby('Score').count().Id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's build a word cloud looking at the 'Summary'  text\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from wordcloud import STOPWORDS\n",
    "\n",
    "# Wordcloud function's input needs to be a single string of text.\n",
    "# Here I'm concatenating all Summaries into a single string.\n",
    "# similarly you can build for Text column\n",
    "\n",
    "reviews_str = reviews_sample.Summary.str.cat()\n",
    "\n",
    "wordcloud = WordCloud(background_color='white').generate(reviews_str)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(wordcloud,interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now let's split the data into Negative (Score is 1 or 2) and Positive (4 or #5) Reviews.\n",
    "negative_reviews = reviews_sample[reviews_sample['Score'].isin([1,2]) ]\n",
    "positive_reviews = reviews_sample[reviews_sample['Score'].isin([4,5]) ]\n",
    "\n",
    "# Transform to single string\n",
    "negative_reviews_str = negative_reviews.Summary.str.cat()\n",
    "positive_reviews_str = positive_reviews.Summary.str.cat()\n",
    "\n",
    "# Create wordclouds\n",
    "wordcloud_negative = WordCloud(background_color='white').generate(negative_reviews_str)\n",
    "wordcloud_positive = WordCloud(background_color='white').generate(positive_reviews_str)\n",
    "\n",
    "# Plot\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax1 = fig.add_subplot(211)\n",
    "ax1.imshow(wordcloud_negative,interpolation='bilinear')\n",
    "ax1.axis(\"off\")\n",
    "ax1.set_title('Reviews with Negative Scores',fontsize=20)\n",
    "ax2 = fig.add_subplot(212)\n",
    "ax2.imshow(wordcloud_positive,interpolation='bilinear')\n",
    "ax2.axis(\"off\")\n",
    "ax2.set_title('Reviews with Positive Scores',fontsize=20)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import ast\n",
    "plt.style.use('fivethirtyeight')\n",
    "# Function for getting the sentiment\n",
    "cp = sns.color_palette()\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Generating sentiment for all the sentence present in the dataset\n",
    "emptyline=[]\n",
    "for row in df['Text']:\n",
    "    vs=analyzer.polarity_scores(row)\n",
    "    emptyline.append(vs)\n",
    "\n",
    "# Creating new dataframe with sentiments    \n",
    "df_sentiments=pd.DataFrame(emptyline)\n",
    "df_sentiments.head(5)\n",
    "\n",
    "# Merging the sentiments back to reviews dataframe\n",
    "df_c = pd.concat([df.reset_index(drop=True), d], axis=1)\n",
    "df_c.head(3)\n",
    "\n",
    "# Convert scores into positive and negetive sentiments using some threshold\n",
    "df_c['Sentiment'] = np.where(df_c['compound'] >= 0 , 'Positive', 'Negative')\n",
    "df_c.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result=df_c['Sentiment'].value_counts()\n",
    "result.plot(kind='bar', rot=0,color='br');\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Recipe 5-3. Applying text similarity functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import package\n",
    "!pip install recordlinkage\n",
    "import recordlinkage\n",
    "\n",
    "#For this demo let us use the inbuilt dataset from recordlinkage library\n",
    "\n",
    "#import data set\n",
    "from recordlinkage.datasets import load_febrl1 \n",
    "\n",
    "#create a dataframe - dfa\n",
    "dfA = load_febrl1()\n",
    "dfA.head()\n",
    "\n",
    "indexer = recordlinkage.BlockIndex(on='given_name')\n",
    "pairs = indexer.index(dfA)\n",
    "\n",
    "print (len(pairs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This cell can take some time to compute.\n",
    "compare_cl = recordlinkage.Compare()\n",
    "\n",
    "compare_cl.string('given_name', 'given_name',method='jarowinkler', label='given_name')\n",
    "compare_cl.string('surname', 'surname', method='jarowinkler', label='surname')\n",
    "compare_cl.exact('date_of_birth', 'date_of_birth', label='date_of_birth')\n",
    "compare_cl.exact('suburb', 'suburb', label='suburb')\n",
    "compare_cl.exact('state', 'state', label='state')\n",
    "compare_cl.string('address_1', 'address_1',method='jarowinkler', label='address_1')\n",
    "\n",
    "features = compare_cl.compute(pairs, dfA)\n",
    "features.sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select all the features except for given_name since its our blocking key\n",
    "features1 = features[['suburb','state','surname','date_of_birth','address_1']]\n",
    "\n",
    "# Unsupervised learning – probabilistic\n",
    "\n",
    "ecm = recordlinkage.ECMClassifier()\n",
    "result_ecm = ecm.learn((features1).astype(int),return_type = 'series')\n",
    "\n",
    "result_ecm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let us use the inbuilt dataset from recordlinkage library\n",
    "\n",
    "from recordlinkage.datasets import load_febrl4\n",
    "\n",
    "dfA, dfB = load_febrl4()\n",
    "dfA.head()\n",
    "\n",
    "# Same as explained previously, considering given_name as blocking index\n",
    "\n",
    "indexer = recordlinkage.BlockIndex(on='given_name')\n",
    "pairs = indexer.index(dfA, dfB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Explanation remains same\n",
    "compare_cl = recordlinkage.Compare()\n",
    "\n",
    "compare_cl.string('given_name', 'given_name',method='jarowinkler', label='given_name')\n",
    "compare_cl.string('surname', 'surname', method='jarowinkler', label='surname')\n",
    "compare_cl.exact('date_of_birth', 'date_of_birth', label='date_of_birth')\n",
    "compare_cl.exact('suburb', 'suburb', label='suburb')\n",
    "compare_cl.exact('state', 'state', label='state')\n",
    "compare_cl.string('address_1', 'address_1',method='jarowinkler', label='address_1')\n",
    "\n",
    "features = compare_cl.compute(pairs, dfA, dfB)\n",
    "\n",
    "features.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select all the features except for given_name since its our blocking key\n",
    "features1 = features[['suburb','state','surname','date_of_birth','address_1']]\n",
    "\n",
    "# unsupervised learning - probablistic\n",
    "ecm = recordlinkage.ECMClassifier()\n",
    "result_ecm = ecm.learn((features1).astype(int),return_type = 'series')\n",
    "\n",
    "result_ecm\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Recipe 5-4. Summarizing Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import BeautifulSoup and urllib libraries to fetch data from Wikipedia.\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "\n",
    "\n",
    "# Function to get data from Wikipedia\n",
    "\n",
    "def get_only_text(url):\n",
    " page = urlopen(url)\n",
    " soup = BeautifulSoup(page)\n",
    " text = ' '.join(map(lambda p: p.text, soup.find_all('p')))\n",
    " print (text) \n",
    " return soup.title.text, text  \n",
    "\n",
    "# Mention the Wikipedia url\n",
    "url=”https://en.wikipedia.org/wiki/Natural_language_processing”\n",
    "\n",
    "# Call the function created above\n",
    "text = get_only_text(url) \n",
    "\n",
    "# Count the number of letters\n",
    "len(''.join(text))\n",
    "# Lets see first 1000 letters from the text\n",
    "text[:1000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import summarize from gensim\n",
    "from gensim.summarization.summarizer import summarize\n",
    "from gensim.summarization import keywords\n",
    "\n",
    "# Convert text to string format\n",
    "text = str(text)\n",
    "\n",
    "#Summarize the text with ratio 0.1 (10% of the total words.)\n",
    "summarize(text, ratio=0.1)\n",
    "\n",
    "#keywords\n",
    "print(keywords(text, ratio=0.1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Install sumy\n",
    "\n",
    "!pip install sumy\n",
    "\n",
    "# Import the packages\n",
    "\n",
    "from sumy.parsers.html import HtmlParser\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "from sumy.nlp.stemmers import Stemmer\n",
    "from sumy.utils import get_stop_words\n",
    "from sumy.summarizers.luhn import LuhnSummarizer \n",
    "\n",
    "# Extracting and summarizing\n",
    "LANGUAGE = \"english\"\n",
    "SENTENCES_COUNT = 10\n",
    "    \n",
    "url=\"https://en.wikipedia.org/wiki/Natural_language_processing\"\n",
    "   \n",
    "parser = HtmlParser.from_url(url, Tokenizer(LANGUAGE))\n",
    "summarizer = LsaSummarizer()\n",
    "summarizer = LsaSummarizer(Stemmer(LANGUAGE))\n",
    "summarizer.stop_words = get_stop_words(LANGUAGE)\n",
    "for sentence in summarizer(parser.document, SENTENCES_COUNT):\n",
    "    print(sentence)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Recipe 5-5. Clustering Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install mpld3\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os\n",
    "import codecs\n",
    "from sklearn import feature_extraction\n",
    "import mpld3\n",
    "from sklearn.metrics.pairwise import cosine_similarity  \n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from sklearn.manifold import MDS\n",
    "\n",
    "\n",
    "#Lets use the same complaint dataset we use for classification\n",
    "Data = pd.read_csv(\"/Consumer_Complaints.csv\",encoding='latin-1')\n",
    "\n",
    "#selecting required columns and rows\n",
    "Data = Data[['consumer_complaint_narrative']]\n",
    "Data = Data[pd.notnull(Data['consumer_complaint_narrative'])]\n",
    "\n",
    "# lets do the clustering for just 200 documents. Its easier to interpret.\n",
    "Data_sample=Data.sample(200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove unwanted symbol\n",
    "\n",
    "Data_sample['consumer_complaint_narrative'] = Data_sample['consumer_complaint_narrative'].str.replace('XXXX','')\n",
    "\n",
    "# Convert dataframe to list\n",
    "complaints = Data_sample['consumer_complaint_narrative'].tolist()\n",
    "\n",
    "# create the rank of documents – we will use it later\n",
    "\n",
    "ranks = []\n",
    "for i in range(1, len(complaints)+1):\n",
    "    ranks.append(i)\n",
    "\n",
    "# Stop Words\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "# Load 'stemmer'\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "# Functions for sentence tokenizer, to remove numeric tokens and raw #punctuation\n",
    "\n",
    "def tokenize_and_stem(text):\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems\n",
    "\n",
    "def tokenize_only(text):\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# tfidf vectorizer \n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, max_features=200000,\n",
    "                                 min_df=0.2, stop_words='english',\n",
    "                                 use_idf=True, tokenizer=tokenize_and_stem, ngram_range=(1,3))\n",
    "\n",
    "#fit the vectorizer to data\n",
    "\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(complaints) \n",
    "terms = tfidf_vectorizer.get_feature_names()\n",
    "print(tfidf_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import Kmeans\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Define number of clusters\n",
    "num_clusters = 6\n",
    "\n",
    "#Running clustering algorithm\n",
    "km = KMeans(n_clusters=num_clusters)\n",
    "km.fit(tfidf_matrix)\n",
    "\n",
    "#final clusters\n",
    "clusters = km.labels_.tolist()\n",
    "complaints_data = { 'rank': ranks, 'complaints': complaints, 'cluster': clusters }\n",
    "frame = pd.DataFrame(complaints_data, index = [clusters] , columns = ['rank', 'cluster'])\n",
    "\n",
    "#number of docs per cluster \n",
    "frame['cluster'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "totalvocab_stemmed = []\n",
    "totalvocab_tokenized = []\n",
    "for i in complaints:\n",
    "    allwords_stemmed = tokenize_and_stem(i) \n",
    "    totalvocab_stemmed.extend(allwords_stemmed) \n",
    "    \n",
    "    allwords_tokenized = tokenize_only(i)\n",
    "    totalvocab_tokenized.extend(allwords_tokenized)\n",
    "\n",
    "vocab_frame = pd.DataFrame({'words': totalvocab_tokenized}, index = totalvocab_stemmed)\n",
    "\n",
    "#sort cluster centers by proximity to centroid\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1] \n",
    "\n",
    "for i in range(num_clusters):\n",
    "    print(\"Cluster %d words:\" % i, end='')\n",
    "    \n",
    "    for ind in order_centroids[i, :6]: \n",
    "        print(' %s' % vocab_frame.ix[terms[ind].split(' ')].values.tolist()[0][0].encode('utf-8', 'ignore'), end=',')\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Similarity\n",
    "\n",
    "similarity_distance = 1 - cosine_similarity(tfidf_matrix)\n",
    "\n",
    "\n",
    "# Convert two components as we're plotting points in a two-dimensional plane\n",
    "mds = MDS(n_components=2, dissimilarity=\"precomputed\", random_state=1)\n",
    "pos = mds.fit_transform(similarity_distance)  # shape (n_components, n_samples)\n",
    "xs, ys = pos[:, 0], pos[:, 1]\n",
    "\n",
    "#Set up colors per clusters using a dict\n",
    "cluster_colors = {0: '#1b9e77', 1: '#d95f02', 2: '#7570b3', 3: '#e7298a', 4: '#66a61e',5: '#D2691E'}\n",
    "\n",
    "#set up cluster names using a dict\n",
    "cluster_names = {0: 'property, based, assist', \n",
    "                 1: 'business, card', \n",
    "                 2: 'authorized, approved, believe', \n",
    "                 3: 'agreement, application,business', \n",
    "                 4: 'closed, applied, additional',\n",
    "                 5: 'applied, card'}\n",
    "\n",
    "# Finally plot it\n",
    "%matplotlib inline \n",
    "\n",
    "#Create data frame that has the result of the MDS and the cluster \n",
    "df = pd.DataFrame(dict(x=xs, y=ys, label=clusters)) \n",
    "groups = df.groupby('label')\n",
    "\n",
    "# Set up plot\n",
    "fig, ax = plt.subplots(figsize=(17, 9)) # set size\n",
    "\n",
    "for name, group in groups:\n",
    "    ax.plot(group.x, group.y, marker='o', linestyle='', ms=20, \n",
    "            label=cluster_names[name], color=cluster_colors[name], \n",
    "            mec='none')\n",
    "    ax.set_aspect('auto')\n",
    "    ax.tick_params(\\\n",
    "        axis= 'x',          \n",
    "        which='both',      \n",
    "        bottom='off',     \n",
    "        top='off',         \n",
    "        labelbottom='off')\n",
    "    ax.tick_params(\\\n",
    "        axis= 'y',        \n",
    "        which='both',    \n",
    "        left='off',     \n",
    "        top='off',       \n",
    "        labelleft='off')\n",
    "    \n",
    "ax.legend(numpoints=1) \n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recipe 5-7. Fake news detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Manipulation \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot the Figures Inline\n",
    "%matplotlib inline\n",
    "\n",
    "#NLP\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from textblob import Word\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Machine Learning\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#importing dataset\n",
    "df = pd.read_csv(' fakenews_dataset.csv')\n",
    "df.shape\n",
    "\n",
    "df['Category'].value_counts()\n",
    "\n",
    "#no. of news per category\n",
    "sns.countplot(x='Category', data=df)\n",
    "\n",
    "#adding additional column for length\n",
    "\n",
    "df['length']=df['News'].str.len()\n",
    "df.head()\n",
    "\n",
    "#Cheking max and min length of the News articles\n",
    "\n",
    "maxlength = df['length'].max()\n",
    "minlength = df['length'].min()\n",
    "maxlength,minlength\n",
    "\n",
    "df.hist(column='length', by='Fake', bins=50,figsize=(12,4),color='orange')\n",
    "\n",
    "#Length of Articles with respect to the various categories:\n",
    "df.hist(column='length', by='Category', bins=50,figsize=(20,10),color='orange')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Pre-Processing\n",
    "\n",
    "df['News'] = df['News'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "print(df['News'].head())\n",
    "\n",
    "df['News'] = df['News'].str.replace('[^\\w\\s]','')\n",
    "print(df['News'].head())\n",
    "\n",
    "The stopwords are imported from the nltk library.\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "df['News'] = df['News'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "df['News'] = df['News'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting into training and testing data\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3, random_state=100, stratify=y)\n",
    "\n",
    "#validate the shape of train and test dataset\n",
    "print (X_train.shape)\n",
    "print (y_train.shape)\n",
    "\n",
    "print (X_test.shape)\n",
    "print (y_test.shape)\n",
    "\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "tfidf_vect.fit(df['News'])\n",
    "xtrain_tfidf =  tfidf_vect.transform(X_train['News'])\n",
    "xtest_tfidf =  tfidf_vect.transform(X_test['News'])\n",
    "\n",
    "def train_model(classifier, feature_vector_train, label, feature_vector_test):\n",
    "   \n",
    "    # fitting \n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predicting\n",
    "    predictions = classifier.predict(feature_vector_test)\n",
    "    \n",
    "        return metrics.accuracy_score(predictions, y_test)\n",
    "\n",
    "\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf, y_train, xtest_tfidf)\n",
    "print (\"Accuracy of Naive Bayes: \", accuracy)\n",
    "\n",
    "accuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf, y_train, xtest_tfidf)\n",
    "print (\"Accuracy of logistic regression: \", accuracy)\n",
    "\n",
    "accuracy = train_model(svm.SVC(), xtrain_tfidf, y_train, xtest_tfidf)\n",
    "print (\"Accuracy of SVM: \", accuracy)\n",
    "\n",
    "accuracy = train_model(RandomForestClassifier(), xtrain_tfidf, y_train, xtest_tfidf)\n",
    "print (\"Accuracy of RandomForest: \", accuracy)\n",
    "\n",
    "#fit the model\n",
    "model=linear_model.LogisticRegression()\n",
    "nb = model.fit(xtrain_tfidf,y_train)\n",
    "nb\n",
    "\n",
    "## Model Results:\n",
    "\n",
    "predictions = nb.predict(xtest_tfidf)\n",
    "predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fine tuning\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, predictions,target_names=[\"Legit\", \"Fake\"]))\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "nb_auc = roc_auc_score(y_test, nb.predict_proba(xtest_tfidf)[:, 1])\n",
    "print(\"AUC for Model: {:.3f}\".format(nb_auc))\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 15,20,100]}\n",
    "\n",
    "cf_model=linear_model.LogisticRegression()\n",
    "grid_search = GridSearchCV(cf_model, param_grid, cv=5)\n",
    "\n",
    "grid_search.fit(xtrain_tfidf, y_train)\n",
    "\n",
    "print(\"Test set score: {:.2f}\".format(grid_search.score(xtest_tfidf, y_test)))\n",
    "\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "print(\"Best estimator:\\n{}\".format(grid_search.best_estimator_))\n",
    "\n",
    "model=linear_model.LogisticRegression(C=20, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
    "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
    "          verbose=0, warm_start=False)\n",
    "nb=model.fit(xtrain_tfidf, y_train)\n",
    "nb\n",
    "\n",
    "print(classification_report(y_test, predictions,target_names=[\"Legit\", \"Fake\"]))\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "nb_auc = roc_auc_score(y_test, nb.predict_proba(xtest_tfidf)[:, 1])\n",
    "print(\"AUC for tuned SVC model: {:.3f}\".format(nb_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recipe 5-8. Movie genre tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the dataset from the below link: \n",
    "https://www.kaggle.com/cryptexcode/mpst-movie-plot-synopses-with-tags#mpst_full_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Let’s import all the basic libraries required for text mining tasks.\n",
    "\n",
    "# Data Manipulation \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot the Figures Inline\n",
    "%matplotlib inline\n",
    "\n",
    "#Natural language processing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from textblob import Word\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#Importing dataset\n",
    "df = pd.read_csv('movies_genres1.csv',encoding = 'ISO-8859-1')\n",
    "df.shape\n",
    "\n",
    "#Top 5 rows to see the data\n",
    "df.head()\n",
    "\n",
    "df[\"desc\"] = df[\"title\"].map(str) + df[\"plot\"]\n",
    "df = df[df['desc'].notnull()]\n",
    "\n",
    "print (df.apply(pd.to_numeric, errors='coerce').sum())\n",
    "\n",
    "df.groupby(['Total_tags']).size()\n",
    "\n",
    "df['desc'] = df['desc'].apply(lambda x:\" \".join(x.lower() for x in x.split()))\n",
    "df['desc'] = df['desc'].str.replace('\\d+', '')\n",
    "df['desc'] = df['desc'].str.replace('[^\\w\\s]','')\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "df['desc'] = df['desc'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "df['desc'] = df['desc'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "\n",
    "df['desc'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create input dataset without including target variable( class column)\n",
    "X = df['desc']\n",
    "X.shape\n",
    "\n",
    "(9501,)\n",
    "\n",
    "\n",
    "#Create the target data with only class column\n",
    "y = df.iloc[:,2:29]\n",
    "y.shape\n",
    "\n",
    "(9501, 27)\n",
    "\n",
    "\n",
    "# splitting into training and testing data\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3, random_state=100, stratify=y)\n",
    "\n",
    "#validate the shape of train and test dataset\n",
    "print (X_train.shape)\n",
    "print (y_train.shape)\n",
    "\n",
    "print (X_test.shape)\n",
    "print (y_test.shape)\n",
    "\n",
    "#Generating features using tfidf\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "tfidf_vect.fit(df['desc'])\n",
    "\n",
    "xtrain_tfidf =  tfidf_vect.transform(X_train)\n",
    "xtest_tfidf =  tfidf_vect.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# initialize binary relevance multi-label classifier with a gaussian naive Bayes base classifier\n",
    "\n",
    "classifier = BinaryRelevance(GaussianNB())\n",
    "\n",
    "# train the algorithms\n",
    "classifier.fit(xtrain_tfidf, y_train)\n",
    "\n",
    "# predict\n",
    "predictions = classifier.predict(xtest_tfidf)\n",
    "\n",
    "#output\n",
    "print(predictions)\n",
    "\n",
    "#Evaluation\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,predictions)\n",
    "\n",
    "metrics.hamming_loss(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the library \n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# define the classifier \n",
    "\n",
    "classifier = BinaryRelevance(\n",
    "    classifier=SVC(),\n",
    "    require_dense=[False, True]\n",
    ")\n",
    "\n",
    "# train\n",
    "classifier.fit(xtrain_tfidf, y_train)\n",
    "\n",
    "# predict\n",
    "predictions = classifier.predict(xtest_tfidf)\n",
    "\n",
    "# evaluation\n",
    "accuracy_score(y_test,predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using classifier chains\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# initialize classifier chains multi-label classifier\n",
    "# with a gaussian naive Bayes base classifier\n",
    "\n",
    "classifier = ClassifierChain(GaussianNB())\n",
    "\n",
    "# train\n",
    "classifier.fit(xtrain_tfidf, y_train)\n",
    "\n",
    "# predict\n",
    "predictions = classifier.predict(xtest_tfidf)\n",
    "\n",
    "accuracy_score(y_test,predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Label Powerset\n",
    "\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# initialize Label Powerset multi-label classifier\n",
    "# with a gaussian naive bayes base classifier\n",
    "\n",
    "classifier = LabelPowerset(GaussianNB())\n",
    "\n",
    "# train\n",
    "\n",
    "classifier.fit(xtrain_tfidf, y_train)\n",
    "\n",
    "# predict\n",
    "\n",
    "predictions = classifier.predict(xtest_tfidf)\n",
    "accuracy_score(y_test,predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#define the parameters\n",
    "\n",
    "parameters = [\n",
    "    {\n",
    "        'classifier': [MultinomialNB()],\n",
    "        'classifier__alpha': [0.7, 1.0],\n",
    "    },\n",
    "    {\n",
    "        'classifier': [RandomForestClassifier()],\n",
    "        'classifier__criterion': ['gini', 'entropy'],\n",
    "        'classifier__n_estimators': [10, 20, 50],\n",
    "    },\n",
    "]\n",
    "\n",
    "# tuning\n",
    "clf = GridSearchCV(LabelPowerset(), parameters, scoring='accuracy')\n",
    "clf.fit(xtrain_tfidf, y_train)\n",
    "\n",
    "#print the best accuracy\n",
    "print (clf.best_params_, clf.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adapted Algorithm\n",
    "#convert the data to matrix \n",
    "y_train = y_train.as_matrix()\n",
    "\n",
    "#import the package\n",
    "from skmultilearn.adapt import MLkNN\n",
    "classifier = MLkNN(k=20)\n",
    "\n",
    "# train\n",
    "classifier.fit(xtrain_tfidf, y_train)\n",
    "\n",
    "# predict\n",
    "predictions = classifier.predict(xtest_tfidf)\n",
    "\n",
    "accuracy_score(y_test,predictions)\n",
    "\n",
    "0.364784286215363\n",
    "\n",
    "# import\n",
    "from skmultilearn.adapt import BRkNNaClassifier\n",
    "classifier = BRkNNaClassifier(k=3)\n",
    "\n",
    "# train\n",
    "classifier.fit(xtrain_tfidf, y_train)\n",
    "\n",
    "# predict\n",
    "predictions = classifier.predict(xtest_tfidf)\n",
    "print(predictions)\n",
    "\n",
    "accuracy_score(y_test,predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.adapt import MLTSVM\n",
    "classifier = MLTSVM(c_k = 2**-1)\n",
    "\n",
    "# train\n",
    "classifier.fit(xtrain_tfidf, y_train)\n",
    "\n",
    "# predict\n",
    "predictions = classifier.predict(xtest_tfidf)\n",
    "\n",
    "accuracy_score(y_test,predictions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
